From bdb5a922391cb54fc7db0b7ef5aad9f25c3f714b Mon Sep 17 00:00:00 2001
From: Torge Matthies <openglfreak@googlemail.com>
Date: Sun, 7 Aug 2022 21:19:26 +0200
Subject: [PATCH 2/8] server,ntdll: Send and receive server requests through
 shared memory.

---
 dlls/ntdll/unix/server.c |  92 ++++++++++++++++++++++++++++++++
 server/Makefile.in       |   2 +-
 server/fd.c              |  81 ++++++++++++++++++++++++++++
 server/file.h            |   5 ++
 server/request.c         |  98 ++++++++++++++++++++++++++++++++++
 server/request.h         |   1 +
 server/thread.c          | 111 ++++++++++++++++++++++++++++++++++++++-
 server/thread.h          |   1 +
 8 files changed, 388 insertions(+), 3 deletions(-)

diff --git a/dlls/ntdll/unix/server.c b/dlls/ntdll/unix/server.c
index 11111111111..11111111111 100644
--- a/dlls/ntdll/unix/server.c
+++ b/dlls/ntdll/unix/server.c
@@ -196,6 +196,78 @@ static DECLSPEC_NORETURN void server_protocol_perror( const char *err )
 }
 
 
+#ifdef __linux__
+
+#define FUTEX_WAIT 0
+#define FUTEX_WAKE 1
+
+/***********************************************************************
+ *           send_request_shm
+ *
+ * Send a request to the server using shared memory.
+ */
+static unsigned int send_request_shm( const struct __server_request_info *req )
+{
+    volatile struct request_shm *request_shm = ntdll_get_thread_data()->request_shm;
+    unsigned int i;
+
+    memcpy( (void*)&request_shm->u.req, &req->u.req, sizeof(req->u.req) );
+    if (req->u.req.request_header.request_size)
+    {
+        char *ptr = (char*)(request_shm + 1);
+        for (i = 0; i < req->data_count; i++)
+        {
+            memcpy( ptr, req->data[i].ptr, req->data[i].size );
+            ptr += req->data[i].size;
+        }
+    }
+
+    while (InterlockedCompareExchange( (void*)&request_shm->futex, 1, 0 ) != 0)
+        YieldProcessor();
+    syscall( __NR_futex, &request_shm->futex, FUTEX_WAKE, 1, NULL, NULL, 0 );
+    return STATUS_SUCCESS;
+}
+
+
+static void read_reply_data( void *buffer, size_t size );
+
+/***********************************************************************
+ *           wait_reply_shm
+ *
+ * Wait for a reply from the server using shared memory.
+ */
+static inline unsigned int wait_reply_shm( struct __server_request_info *req )
+{
+    volatile struct request_shm *request_shm = ntdll_get_thread_data()->request_shm;
+    char *data_ptr = (char*)(request_shm + 1) + req->u.req.request_header.request_size;
+    unsigned int copy_limit = (char*)request_shm + REQUEST_SHM_SIZE - data_ptr;
+    int val;
+
+    while ((val = request_shm->futex) != 0)
+    {
+        if (val == -1)
+            abort_thread(0);
+        syscall( __NR_futex, &request_shm->futex, FUTEX_WAIT, val, NULL, NULL, 0 );
+    }
+
+    memcpy( &req->u.reply, (void*)&request_shm->u.reply, sizeof(req->u.reply) );
+    if (req->u.reply.reply_header.reply_size)
+    {
+        if (req->u.reply.reply_header.reply_size > copy_limit)
+        {
+            memcpy( req->reply_data, data_ptr, copy_limit );
+            read_reply_data( (char*)req->reply_data + copy_limit,
+                             req->u.reply.reply_header.reply_size - copy_limit );
+        }
+        else
+            memcpy( req->reply_data, data_ptr, req->u.reply.reply_header.reply_size );
+    }
+    return req->u.reply.reply_header.error;
+}
+
+#endif /* defined(__linux__) */
+
+
 /***********************************************************************
  *           send_request
  *
@@ -302,6 +374,20 @@ static inline unsigned int wait_reply( struct __server_request_info *req )
 }
 
 
+#ifdef __linux__
+
+unsigned int server_call_unlocked_shm( void *req_ptr )
+{
+    struct __server_request_info * const req = req_ptr;
+    unsigned int ret;
+
+    if ((ret = send_request_shm( req ))) return ret;
+    return wait_reply_shm( req );
+}
+
+#endif
+
+
 /***********************************************************************
  *           server_call_unlocked
  */
@@ -310,6 +396,12 @@ unsigned int server_call_unlocked( void *req_ptr )
     struct __server_request_info * const req = req_ptr;
     unsigned int ret;
 
+#ifdef __linux__
+    if (ntdll_get_thread_data()->request_shm &&
+        sizeof(req->u.req) + req->u.req.request_header.request_size < REQUEST_SHM_SIZE)
+        return server_call_unlocked_shm( req_ptr );
+#endif
+
     if ((ret = send_request( req ))) return ret;
     return wait_reply( req );
 }
diff --git a/server/Makefile.in b/server/Makefile.in
index 11111111111..11111111111 100644
--- a/server/Makefile.in
+++ b/server/Makefile.in
@@ -52,7 +52,7 @@ SOURCES = \
 	winstation.c
 
 UNIX_CFLAGS = $(DBUS_CFLAGS)
-UNIX_LIBS = $(LDEXECFLAGS) $(RT_LIBS) $(INOTIFY_LIBS) $(PROCSTAT_LIBS) $(DBUS_LIBS) -flto=auto -flto-partition=one -fdevirtualize-at-ltrans
+UNIX_LIBS = $(LDEXECFLAGS) $(RT_LIBS) $(INOTIFY_LIBS) $(PROCSTAT_LIBS) $(DBUS_LIBS) $(PTHREAD_LIBS) -flto=auto -flto-partition=one -fdevirtualize-at-ltrans
 EXTRADEFS = -flto=auto -flto-partition=one -fdevirtualize-at-ltrans
 
 unicode_EXTRADEFS = -DNLSDIR="\"${nlsdir}\"" -DBIN_TO_NLSDIR=\"`${MAKEDEP} -R ${bindir} ${nlsdir}`\"
diff --git a/server/fd.c b/server/fd.c
index 11111111111..11111111111 100644
--- a/server/fd.c
+++ b/server/fd.c
@@ -26,6 +26,7 @@
 #include <errno.h>
 #include <fcntl.h>
 #include <limits.h>
+#include <pthread.h>
 #include <signal.h>
 #include <stdarg.h>
 #include <stdio.h>
@@ -160,6 +161,7 @@ struct fd
     unsigned int         signaled :1; /* is the fd signaled? */
     unsigned int         fs_locks :1; /* can we use filesystem locks for this fd? */
     int                  poll_index;  /* index of fd in poll array */
+    int                  poll_generation; /* generation that this fd was added to the poll array in */
     struct async_queue   read_q;      /* async readers of this fd */
     struct async_queue   write_q;     /* async writers of this fd */
     struct async_queue   wait_q;      /* other async waiters of this fd */
@@ -475,6 +477,10 @@ static void set_user_shared_data_time(void)
         user_shared_data->QpcBias = qpc_bias;
 }
 
+pthread_mutex_t global_lock = PTHREAD_MUTEX_INITIALIZER;
+int poll_exit_pipe[2];
+struct fd *poll_exit_fd;
+
 void set_current_time(void)
 {
     static const timeout_t ticks_1601_to_1970 = (timeout_t)86400 * (369 * 365 + 89) * TICKS_PER_SEC;
@@ -570,6 +576,7 @@ static int nb_users;                        /* count of array entries actually i
 static int active_users;                    /* current number of active users */
 static int allocated_users;                 /* count of allocated entries in the array */
 static struct fd **freelist;                /* list of free entries in the array */
+unsigned long poll_generation;              /* current poll array generation */
 
 static int get_next_timeout(void);
 
@@ -648,20 +655,27 @@ static inline void main_loop_epoll(void)
 
     if (epoll_fd == -1) return;
 
+    pthread_mutex_lock( &global_lock );
     while (active_users)
     {
+        unsigned long generation;
+
         timeout = get_next_timeout();
 
         if (!active_users) break;  /* last user removed by a timeout */
         if (epoll_fd == -1) break;  /* an error occurred with epoll */
 
+        generation = poll_generation;
+        pthread_mutex_unlock( &global_lock );
         ret = epoll_wait( epoll_fd, events, ARRAY_SIZE( events ), timeout );
+        pthread_mutex_lock( &global_lock );
         set_current_time();
 
         /* put the events into the pollfd array first, like poll does */
         for (i = 0; i < ret; i++)
         {
             int user = events[i].data.u32;
+            if (user >= nb_users || pollfd[user].fd == -1 || poll_users[user]->poll_generation > generation) continue;
             pollfd[user].revents = events[i].events;
         }
 
@@ -669,9 +683,11 @@ static inline void main_loop_epoll(void)
         for (i = 0; i < ret; i++)
         {
             int user = events[i].data.u32;
+            if (user >= nb_users || pollfd[user].fd == -1 || poll_users[user]->poll_generation > generation) continue;
             if (pollfd[user].revents) fd_poll_event( poll_users[user], pollfd[user].revents );
         }
     }
+    pthread_mutex_unlock( &global_lock );
 }
 
 #elif defined(HAVE_KQUEUE)
@@ -742,13 +758,18 @@ static inline void main_loop_epoll(void)
 
     if (kqueue_fd == -1) return;
 
+    pthread_mutex_lock( &global_lock );
     while (active_users)
     {
+        unsigned long generation;
+
         timeout = get_next_timeout();
 
         if (!active_users) break;  /* last user removed by a timeout */
         if (kqueue_fd == -1) break;  /* an error occurred with kqueue */
 
+        generation = poll_generation;
+        pthread_mutex_unlock( &global_lock );
         if (timeout != -1)
         {
             struct timespec ts;
@@ -758,6 +779,7 @@ static inline void main_loop_epoll(void)
             ret = kevent( kqueue_fd, NULL, 0, events, ARRAY_SIZE( events ), &ts );
         }
         else ret = kevent( kqueue_fd, NULL, 0, events, ARRAY_SIZE( events ), NULL );
+        pthread_mutex_lock( &global_lock );
 
         set_current_time();
 
@@ -765,11 +787,13 @@ static inline void main_loop_epoll(void)
         for (i = 0; i < ret; i++)
         {
             long user = (long)events[i].udata;
+            if (user >= nb_users || pollfd[user].fd == -1 || poll_users[user]->poll_generation > generation) continue;
             pollfd[user].revents = 0;
         }
         for (i = 0; i < ret; i++)
         {
             long user = (long)events[i].udata;
+            if (user >= nb_users || pollfd[user].fd == -1 || poll_users[user]->poll_generation > generation) continue;
             if (events[i].filter == EVFILT_READ) pollfd[user].revents |= POLLIN;
             else if (events[i].filter == EVFILT_WRITE) pollfd[user].revents |= POLLOUT;
             if (events[i].flags & EV_EOF) pollfd[user].revents |= POLLHUP;
@@ -780,10 +804,12 @@ static inline void main_loop_epoll(void)
         for (i = 0; i < ret; i++)
         {
             long user = (long)events[i].udata;
+            if (user >= nb_users || pollfd[user].fd == -1 || poll_users[user]->poll_generation > generation) continue;
             if (pollfd[user].revents) fd_poll_event( poll_users[user], pollfd[user].revents );
             pollfd[user].revents = 0;
         }
     }
+    pthread_mutex_unlock( &global_lock );
 }
 
 #elif defined(USE_EVENT_PORTS)
@@ -844,14 +870,19 @@ static inline void main_loop_epoll(void)
 
     if (port_fd == -1) return;
 
+    pthread_mutex_lock( &global_lock );
     while (active_users)
     {
+        unsigned long generation;
+
         timeout = get_next_timeout();
         nget = 1;
 
         if (!active_users) break;  /* last user removed by a timeout */
         if (port_fd == -1) break;  /* an error occurred with event completion */
 
+        generation = poll_generation;
+        pthread_mutex_unlock( &global_lock );
         if (timeout != -1)
         {
             struct timespec ts;
@@ -861,6 +892,7 @@ static inline void main_loop_epoll(void)
             ret = port_getn( port_fd, events, ARRAY_SIZE( events ), &nget, &ts );
         }
         else ret = port_getn( port_fd, events, ARRAY_SIZE( events ), &nget, NULL );
+        pthread_mutex_lock( &global_lock );
 
 	if (ret == -1) break;  /* an error occurred with event completion */
 
@@ -870,6 +902,7 @@ static inline void main_loop_epoll(void)
         for (i = 0; i < nget; i++)
         {
             long user = (long)events[i].portev_user;
+            if (user >= nb_users || pollfd[user].fd == -1 || poll_users[user]->poll_generation > generation) continue;
             pollfd[user].revents = events[i].portev_events;
         }
 
@@ -877,6 +910,7 @@ static inline void main_loop_epoll(void)
         for (i = 0; i < nget; i++)
         {
             long user = (long)events[i].portev_user;
+            if (user >= nb_users || pollfd[user].fd == -1 || poll_users[user]->poll_generation > generation) continue;
             if (pollfd[user].revents) fd_poll_event( poll_users[user], pollfd[user].revents );
             /* if we are still interested, reassociate the fd */
             if (pollfd[user].fd != -1) {
@@ -884,6 +918,7 @@ static inline void main_loop_epoll(void)
             }
         }
     }
+    pthread_mutex_unlock( &global_lock );
 }
 
 #else /* HAVE_KQUEUE */
@@ -932,6 +967,7 @@ static int add_poll_user( struct fd *fd )
     pollfd[ret].events = 0;
     pollfd[ret].revents = 0;
     poll_users[ret] = fd;
+    fd->poll_generation = ++poll_generation;
     active_users++;
     return ret;
 }
@@ -1017,30 +1053,65 @@ static int get_next_timeout(void)
     return ret;
 }
 
+static void poll_exit_poll_event( struct fd *fd, int event )
+{
+    char dummy;
+    read( fd->unix_fd, &dummy, sizeof(dummy) );
+}
+
+static const struct fd_ops poll_exit_fd_ops =
+{
+    NULL,                        /* get_poll_events */
+    poll_exit_poll_event,        /* poll_event */
+    NULL,                        /* flush */
+    NULL,                        /* get_fd_type */
+    NULL,                        /* ioctl */
+    NULL,                        /* queue_async */
+    NULL                         /* reselect_async */
+};
+
+static int create_poll_exit_fd( void )
+{
+    if (pipe( poll_exit_pipe )) return 0;
+    poll_exit_fd = create_anonymous_fd( &poll_exit_fd_ops, poll_exit_pipe[0], NULL, 0 );
+    if (!poll_exit_fd) return 0;
+    set_fd_events( poll_exit_fd, POLLIN );
+    return 1;
+}
+
 /* server main poll() loop */
 void main_loop(void)
 {
     int i, ret, timeout;
 
+    if (!create_poll_exit_fd()) return;
+
     set_current_time();
     server_start_time = current_time;
 
     main_loop_epoll();
     /* fall through to normal poll loop */
 
+    pthread_mutex_lock( &global_lock );
     while (active_users)
     {
+        unsigned long generation;
+
         timeout = get_next_timeout();
 
         if (!active_users) break;  /* last user removed by a timeout */
 
+        generation = poll_generation;
+        pthread_mutex_unlock( &global_lock );
         ret = poll( pollfd, nb_users, timeout );
+        pthread_mutex_lock( &global_lock );
         set_current_time();
 
         if (ret > 0)
         {
             for (i = 0; i < nb_users; i++)
             {
+                if (pollfd[i].fd == -1 || poll_users[i]->poll_generation > generation) continue;
                 if (pollfd[i].revents)
                 {
                     fd_poll_event( poll_users[i], pollfd[i].revents );
@@ -1049,6 +1120,14 @@ void main_loop(void)
             }
         }
     }
+    pthread_mutex_unlock( &global_lock );
+}
+
+/* global lock must be held */
+void force_exit_poll( void )
+{
+    static char zero;
+    write( poll_exit_pipe[1], &zero, sizeof(zero) );
 }
 
 
@@ -1778,6 +1857,8 @@ void set_fd_events( struct fd *fd, int events )
     int user = fd->poll_index;
     assert( poll_users[user] == fd );
 
+    fd->poll_generation = ++poll_generation;
+
     set_fd_epoll_events( fd, user, events );
 
     if (events == -1)  /* stop waiting on this fd completely */
diff --git a/server/file.h b/server/file.h
index 11111111111..11111111111 100644
--- a/server/file.h
+++ b/server/file.h
@@ -21,6 +21,7 @@
 #ifndef __WINE_SERVER_FILE_H
 #define __WINE_SERVER_FILE_H
 
+#include <pthread.h>
 #include <sys/types.h>
 #include <sys/stat.h>
 
@@ -80,6 +81,9 @@ struct fd_ops
 
 /* file descriptor functions */
 
+extern pthread_mutex_t global_lock;
+extern unsigned long poll_generation;
+
 extern struct fd *alloc_pseudo_fd( const struct fd_ops *fd_user_ops, struct object *user,
                                    unsigned int options );
 extern struct fd *open_fd( struct fd *root, const char *name, struct unicode_str nt_name,
@@ -133,6 +137,7 @@ extern void no_fd_queue_async( struct fd *fd, struct async *async, int type, int
 extern void default_fd_queue_async( struct fd *fd, struct async *async, int type, int count );
 extern void default_fd_reselect_async( struct fd *fd, struct async_queue *queue );
 extern void main_loop(void);
+extern void force_exit_poll(void);
 extern void remove_process_locks( struct process *process );
 
 static inline struct fd *get_obj_fd( struct object *obj ) { return obj->ops->get_fd( obj ); }
diff --git a/server/request.c b/server/request.c
index 11111111111..11111111111 100644
--- a/server/request.c
+++ b/server/request.c
@@ -261,6 +261,104 @@ void write_reply( struct thread *thread )
         fatal_protocol_error( thread, "reply write: %s\n", strerror( errno ));
 }
 
+/* send a reply to the current thread */
+void send_reply_shm( union generic_reply *reply, struct request_shm *request_shm, data_size_t req_data_size )
+{
+    char *data_ptr = (char*)(request_shm + 1) + req_data_size;
+    unsigned int copy_limit = (char*)request_shm + REQUEST_SHM_SIZE - data_ptr;
+    int ret;
+
+    /* fixed data is already written */
+    if (!current->reply_size)
+        return;
+
+    if (current->reply_size <= copy_limit)
+    {
+        memcpy( data_ptr, current->reply_data, current->reply_size );
+        if (current->reply_data != current->rep_data) free( current->reply_data );
+        current->reply_data = NULL;
+        return;
+    }
+
+    memcpy( data_ptr, current->reply_data, copy_limit );
+    current->reply_towrite = current->reply_size - copy_limit;
+
+    if ((ret = write( get_unix_fd( current->reply_fd ),
+                      (char *)current->reply_data + current->reply_size - current->reply_towrite,
+                      current->reply_towrite )) >= 0)
+    {
+        if (!(current->reply_towrite -= ret))
+        {
+            if (current->reply_data != current->rep_data) free( current->reply_data );
+            current->reply_data = NULL;
+        }
+        else
+        {
+            /* couldn't write it all, wait for POLLOUT */
+            set_fd_events( current->reply_fd, POLLOUT );
+            set_fd_events( current->request_fd, 0 );
+        }
+        return;
+    }
+    if (errno == EPIPE)
+        kill_thread( current, 0 );  /* normal death */
+    else if (errno != EWOULDBLOCK && (EWOULDBLOCK == EAGAIN || errno != EAGAIN))
+        fatal_protocol_error( current, "reply write: %s\n", strerror( errno ));
+}
+
+/* call a request handler using shared memory */
+static void call_req_handler_shm( struct thread *thread, struct request_shm *request_shm )
+{
+    enum request req = thread->req.request_header.req;
+    data_size_t data_size = thread->req.request_header.request_size;
+
+    current = thread;
+    current->reply_size = 0;
+    clear_error();
+    memset( &request_shm->u.reply, 0, sizeof(request_shm->u.reply) );
+
+    if (debug_level) trace_request();
+
+    if (req < REQ_NB_REQUESTS)
+        req_handlers[req]( &current->req, &request_shm->u.reply );
+    else
+        set_error( STATUS_NOT_IMPLEMENTED );
+
+    if (current)
+    {
+        if (current->reply_fd)
+        {
+            request_shm->u.reply.reply_header.error = current->error;
+            request_shm->u.reply.reply_header.reply_size = current->reply_size;
+            if (debug_level) trace_reply( req, &request_shm->u.reply );
+            send_reply_shm( &request_shm->u.reply, request_shm, data_size );
+        }
+        else
+        {
+            current->exit_code = 1;
+            kill_thread( current, 1 );  /* no way to continue without reply fd */
+        }
+    }
+    current = NULL;
+}
+
+/* read a request from a thread using shared memory */
+void read_request_shm( struct thread *thread, struct request_shm *request_shm )
+{
+    void *orig_req_data = thread->req_data;
+    data_size_t data_size;
+
+    memcpy( &thread->req, &request_shm->u.req, sizeof(thread->req) );
+    data_size = thread->req.request_header.request_size;
+    if (data_size)
+        thread->req_data = request_shm + 1;
+
+    call_req_handler_shm( thread, request_shm );
+
+    if (data_size)
+        thread->req_data = orig_req_data;
+}
+
 /* send a reply to the current thread */
 void send_reply( union generic_reply *reply )
 {
diff --git a/server/request.h b/server/request.h
index 11111111111..11111111111 100644
--- a/server/request.h
+++ b/server/request.h
@@ -52,6 +52,7 @@ extern const struct object_attributes *get_req_object_attributes( const struct s
 extern const void *get_req_data_after_objattr( const struct object_attributes *attr, data_size_t *len );
 extern int receive_fd( struct process *process );
 extern int send_client_fd( struct process *process, int fd, obj_handle_t handle );
+extern void read_request_shm( struct thread *thread, struct request_shm *request_shm );
 extern void read_request( struct thread *thread );
 extern void write_reply( struct thread *thread );
 extern timeout_t monotonic_counter(void);
diff --git a/server/thread.c b/server/thread.c
index 11111111111..11111111111 100644
--- a/server/thread.c
+++ b/server/thread.c
@@ -23,6 +23,7 @@
 #include <assert.h>
 #include <errno.h>
 #include <fcntl.h>
+#include <pthread.h>
 #include <signal.h>
 #include <stdarg.h>
 #include <stdio.h>
@@ -44,6 +45,9 @@
 #ifdef HAVE_SYS_RESOURCE_H
 #include <sys/resource.h>
 #endif
+#ifdef HAVE_SYS_SYSCALL_H
+#include <sys/syscall.h>
+#endif
 
 #include "ntstatus.h"
 #define WIN32_NO_STATUS
@@ -378,6 +382,7 @@ static inline void init_thread_structure( struct thread *thread )
 #ifdef __linux__
     thread->request_shm_fd  = -1;
     thread->request_shm     = NULL;
+    thread->request_shm_thread_running = 0;
 #endif
     thread->state           = RUNNING;
     thread->exit_code       = 0;
@@ -446,6 +451,86 @@ static struct context *create_thread_context( struct thread *thread )
 }
 
 
+#ifdef __linux__
+
+static void handle_shm_request( struct thread *thread, struct request_shm *request_shm )
+{
+    set_current_time();
+    read_request_shm( thread, request_shm );
+}
+
+
+#define FUTEX_WAIT 0
+#define FUTEX_WAKE 1
+
+static void *request_shm_thread(void *param)
+{
+    struct thread *thread = param;
+    int request_shm_fd;
+    volatile struct request_shm *request_shm;
+    unsigned long generation = 0;
+
+    pthread_mutex_lock( &global_lock );
+    request_shm_fd = thread->request_shm_fd;
+    request_shm = thread->request_shm;
+    pthread_mutex_unlock( &global_lock );
+
+    for (;;)
+    {
+        int val;
+
+        while ((val = request_shm->futex) != 1)
+        {
+            if (val == -1)
+                goto done;
+            else if (val != 0)
+                fatal_protocol_error( thread, "unknown futex state %d\n", val );
+            syscall( __NR_futex, &request_shm->futex, FUTEX_WAIT, val, NULL, NULL, 0 );
+        }
+
+        pthread_mutex_lock( &global_lock );
+        generation = poll_generation;
+
+        val = request_shm->futex;
+        if (val != 1)
+        {
+            if (val != -1)
+                fatal_protocol_error( thread, "unknown futex state %d\n", val );
+            goto done_locked;
+        }
+
+        __asm__ __volatile__ ("" ::: "memory");
+        handle_shm_request( thread, (struct request_shm *)request_shm );
+        __asm__ __volatile__ ("" ::: "memory");
+
+        request_shm_fd = thread->request_shm_fd;
+        request_shm = thread->request_shm;
+        if (!request_shm_fd || !request_shm)
+            goto done_locked;
+        val = __sync_val_compare_and_swap( &request_shm->futex, 1, 0 );
+        if (val != 1 && val != -1)
+            fatal_protocol_error( thread, "unknown futex state %d\n", val );
+        pthread_mutex_unlock( &global_lock );
+        syscall( __NR_futex, &request_shm->futex, FUTEX_WAKE, 1, NULL, NULL, 0 );
+        if (poll_generation != generation)
+            force_exit_poll();
+    }
+
+done:
+    pthread_mutex_lock( &global_lock );
+done_locked:
+    if (request_shm_fd != -1) close( request_shm_fd );
+    if (request_shm) munmap( (void*)request_shm, REQUEST_SHM_SIZE );
+    release_object( thread );
+    pthread_mutex_unlock( &global_lock );
+    if (poll_generation != generation)
+        force_exit_poll();
+    return NULL;
+}
+
+#endif /* defined(__linux__) */
+
+
 static volatile void *init_queue_mapping( struct thread *thread )
 {
     struct unicode_str name;
@@ -504,6 +589,9 @@ struct thread *create_thread( int fd, struct process *process, const struct secu
     struct desktop *desktop;
     struct thread *thread;
     int request_pipe[2];
+#ifdef __linux__
+    pthread_t pthread;
+#endif
 
     if (memory_barrier_obj)
         grab_object( &memory_barrier_obj->obj );
@@ -596,6 +684,16 @@ struct thread *create_thread( int fd, struct process *process, const struct secu
         release_object( thread );
         return NULL;
     }
+
+    grab_object( thread );
+    if (pthread_create( &pthread, NULL, request_shm_thread, thread ))
+    {
+        release_object( thread );
+        release_object( thread );
+        return NULL;
+    }
+    pthread_detach( pthread );
+    thread->request_shm_thread_running = 1;
 #endif
 
     if (do_fsync())
@@ -666,8 +764,16 @@ static void cleanup_thread( struct thread *thread )
     if (thread->reply_fd) release_object( thread->reply_fd );
     if (thread->wait_fd) release_object( thread->wait_fd );
 #ifdef __linux__
-    if (thread->request_shm_fd != -1) close( thread->request_shm_fd );
-    if (thread->request_shm) munmap( (void*)thread->request_shm, REQUEST_SHM_SIZE );
+    if (thread->request_shm)
+    {
+        __atomic_exchange_n( &thread->request_shm->futex, -1, __ATOMIC_SEQ_CST );
+        syscall( __NR_futex, &thread->request_shm->futex, FUTEX_WAKE, 1, NULL, NULL, 0 );
+    }
+    if (!thread->request_shm_thread_running)
+    {
+        if (thread->request_shm_fd != -1) close( thread->request_shm_fd );
+        if (thread->request_shm) munmap( (void*)thread->request_shm, REQUEST_SHM_SIZE );
+    }
 #endif
     cleanup_clipboard_thread(thread);
     destroy_thread_windows( thread );
@@ -695,6 +801,7 @@ static void cleanup_thread( struct thread *thread )
 #ifdef __linux__
     thread->request_shm_fd = -1;
     thread->request_shm = NULL;
+    thread->request_shm_thread_running = 0;
 #endif
     thread->desktop = 0;
     thread->desc = NULL;
diff --git a/server/thread.h b/server/thread.h
index 11111111111..11111111111 100644
--- a/server/thread.h
+++ b/server/thread.h
@@ -93,6 +93,7 @@ struct thread
 #ifdef __linux__
     int                    request_shm_fd; /* request shared memory fd */
     volatile struct request_shm *request_shm; /* shared memory for receiving and sending client requests/replies */
+    int                    request_shm_thread_running;
 #endif
     enum run_state         state;         /* running state */
     int                    exit_code;     /* thread exit code */
-- 
0.0.0

