From: Zebediah Figura <zfigura@codeweavers.com>
Subject: [PATCH 1/2] server: Add helper functions to perform atomic stores.
Message-Id: <20210823205439.165512-1-zfigura@codeweavers.com>
Date: Mon, 23 Aug 2021 15:54:38 -0500

Signed-off-by: Zebediah Figura <zfigura@codeweavers.com>
---
 server/fd.c | 61 ++++++++++++++++++++++++++++-------------------------
 1 file changed, 32 insertions(+), 29 deletions(-)

diff --git a/server/fd.c b/server/fd.c
index de7c5d7e36d..60555032f21 100644
--- a/server/fd.c
+++ b/server/fd.c
@@ -420,6 +420,37 @@ static UINT64 multiply_tsc(UINT64 a, UINT64 b)
     return (ah * bh) + (m >> 32);
 }
 
+static void atomic_store_ulonglong(volatile ULONGLONG *ptr, ULONGLONG value)
+{
+    /* on x86 there should be total store order guarantees, so volatile is
+     * enough to ensure the stores aren't reordered by the compiler, and then
+     * they will always be seen in-order from other CPUs. On other archs, we
+     * need atomic intrinsics to guarantee that. */
+#if defined(__i386__) || defined(__x86_64__)
+    *ptr = value;
+#else
+    __atomic_store_n(ptr, value, __ATOMIC_SEQ_CST);
+#endif
+}
+
+static void atomic_store_ulong(volatile ULONG *ptr, ULONG value)
+{
+#if defined(__i386__) || defined(__x86_64__)
+    *ptr = value;
+#else
+    __atomic_store_n(ptr, value, __ATOMIC_SEQ_CST);
+#endif
+}
+
+static void atomic_store_long(volatile LONG *ptr, LONG value)
+{
+#if defined(__i386__) || defined(__x86_64__)
+    *ptr = value;
+#else
+    __atomic_store_n(ptr, value, __ATOMIC_SEQ_CST);
+#endif
+}
+
 static void set_user_shared_data_time(void)
 {
     timeout_t tick_count = monotonic_time / 10000;
@@ -450,45 +472,22 @@ static void set_user_shared_data_time(void)
         qpc_bias = monotonic_time - tsc;
     }
 
-    /* on X86 there should be total store order guarantees, so volatile is enough
-     * to ensure the stores aren't reordered by the compiler, and then they will
-     * always be seen in-order from other CPUs. On other archs, we need atomic
-     * intrinsics to guarantee that. */
-#if defined(__i386__) || defined(__x86_64__)
-    user_shared_data->SystemTime.High2Time = current_time >> 32;
-    user_shared_data->SystemTime.LowPart   = current_time;
-    user_shared_data->SystemTime.High1Time = current_time >> 32;
+    atomic_store_long(&user_shared_data->SystemTime.High2Time, current_time >> 32);
+    atomic_store_ulong(&user_shared_data->SystemTime.LowPart, current_time);
+    atomic_store_long(&user_shared_data->SystemTime.High1Time, current_time >> 32);
 
-    user_shared_data->InterruptTime.High2Time = monotonic_time >> 32;
-    user_shared_data->InterruptTime.LowPart   = monotonic_time;
-    user_shared_data->InterruptTime.High1Time = monotonic_time >> 32;
+    atomic_store_long(&user_shared_data->InterruptTime.High2Time, monotonic_time >> 32);
+    atomic_store_ulong(&user_shared_data->InterruptTime.LowPart, monotonic_time);
+    atomic_store_long(&user_shared_data->InterruptTime.High1Time, monotonic_time >> 32);
 
-    user_shared_data->TickCount.High2Time = tick_count >> 32;
-    user_shared_data->TickCount.LowPart   = tick_count;
-    user_shared_data->TickCount.High1Time = tick_count >> 32;
-    *(volatile ULONG *)&user_shared_data->TickCountLowDeprecated = tick_count;
-    if (qpc_bypass & SHARED_GLOBAL_FLAGS_QPC_BYPASS_USE_HV_PAGE)
-        hypervisor_shared_data->QpcBias = qpc_bias;
-    else
-        user_shared_data->QpcBias = qpc_bias;
-#else
-    __atomic_store_n(&user_shared_data->SystemTime.High2Time, current_time >> 32, __ATOMIC_SEQ_CST);
-    __atomic_store_n(&user_shared_data->SystemTime.LowPart, current_time, __ATOMIC_SEQ_CST);
-    __atomic_store_n(&user_shared_data->SystemTime.High1Time, current_time >> 32, __ATOMIC_SEQ_CST);
-
-    __atomic_store_n(&user_shared_data->InterruptTime.High2Time, monotonic_time >> 32, __ATOMIC_SEQ_CST);
-    __atomic_store_n(&user_shared_data->InterruptTime.LowPart, monotonic_time, __ATOMIC_SEQ_CST);
-    __atomic_store_n(&user_shared_data->InterruptTime.High1Time, monotonic_time >> 32, __ATOMIC_SEQ_CST);
-
-    __atomic_store_n(&user_shared_data->TickCount.High2Time, tick_count >> 32, __ATOMIC_SEQ_CST);
-    __atomic_store_n(&user_shared_data->TickCount.LowPart, tick_count, __ATOMIC_SEQ_CST);
-    __atomic_store_n(&user_shared_data->TickCount.High1Time, tick_count >> 32, __ATOMIC_SEQ_CST);
-    __atomic_store_n(&user_shared_data->TickCountLowDeprecated, tick_count, __ATOMIC_SEQ_CST);
-    if (qpc_bypass & SHARED_GLOBAL_FLAGS_QPC_BYPASS_USE_HV_PAGE)
-        __atomic_store_n(&hypervisor_shared_data->QpcBias, qpc_bias, __ATOMIC_SEQ_CST);
-    else
-        __atomic_store_n(&user_shared_data->QpcBias, qpc_bias, __ATOMIC_SEQ_CST);
-#endif
+    atomic_store_long(&user_shared_data->TickCount.High2Time, tick_count >> 32);
+    atomic_store_ulong(&user_shared_data->TickCount.LowPart, tick_count);
+    atomic_store_long(&user_shared_data->TickCount.High1Time, tick_count >> 32);
+    atomic_store_ulong(&user_shared_data->TickCountLowDeprecated, tick_count);
+    if (qpc_bypass & SHARED_GLOBAL_FLAGS_QPC_BYPASS_USE_HV_PAGE)
+        atomic_store_ulonglong(&hypervisor_shared_data->QpcBias, qpc_bias);
+    else
+        atomic_store_ulonglong(&user_shared_data->QpcBias, qpc_bias);
 }
 
 void set_current_time(void)

-- 
2.30.2

